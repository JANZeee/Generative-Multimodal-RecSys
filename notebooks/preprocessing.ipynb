{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d21ad6d6-4828-4bc1-b9d4-0c0ce3be2de8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Loading Handmade Reviews ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Handmade_Products.jsonl.gz: 10000it [00:00, 76473.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Loading Handmade Metadata ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading meta_Handmade_Products.jsonl.gz: 10000it [00:00, 23189.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handmade Reviews DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 10 columns):\n",
      " #   Column             Non-Null Count  Dtype  \n",
      "---  ------             --------------  -----  \n",
      " 0   rating             10000 non-null  float64\n",
      " 1   title              10000 non-null  object \n",
      " 2   text               10000 non-null  object \n",
      " 3   images             10000 non-null  object \n",
      " 4   asin               10000 non-null  object \n",
      " 5   parent_asin        10000 non-null  object \n",
      " 6   user_id            10000 non-null  object \n",
      " 7   timestamp          10000 non-null  int64  \n",
      " 8   helpful_vote       10000 non-null  int64  \n",
      " 9   verified_purchase  10000 non-null  bool   \n",
      "dtypes: bool(1), float64(1), int64(2), object(6)\n",
      "memory usage: 713.0+ KB\n",
      "\n",
      "--- First 3 rows of Handmade Reviews ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>images</th>\n",
       "      <th>asin</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>user_id</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>helpful_vote</th>\n",
       "      <th>verified_purchase</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Beautiful colors</td>\n",
       "      <td>I bought one for myself and one for my grandda...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B08GPJ1MSN</td>\n",
       "      <td>B08GPJ1MSN</td>\n",
       "      <td>AF7OANMNHQJC3PD4HRPX2FATECPA</td>\n",
       "      <td>1621607495111</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>You simply must order order more than one!</td>\n",
       "      <td>I’ve ordered three bows so far. Have not been ...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B084TWHS7W</td>\n",
       "      <td>B084TWHS7W</td>\n",
       "      <td>AGMJ3EMDVL6OWBJF7CA5RGJLXN5A</td>\n",
       "      <td>1587762946965</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Great</td>\n",
       "      <td>As pictured. Used a frame from the dollar stor...</td>\n",
       "      <td>[]</td>\n",
       "      <td>B07V3NRQC4</td>\n",
       "      <td>B07V3NRQC4</td>\n",
       "      <td>AEYORY2AVPMCPDV57CE337YU5LXA</td>\n",
       "      <td>1591448951297</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   rating                                       title  \\\n",
       "0     5.0                            Beautiful colors   \n",
       "1     5.0  You simply must order order more than one!   \n",
       "2     5.0                                       Great   \n",
       "\n",
       "                                                text images        asin  \\\n",
       "0  I bought one for myself and one for my grandda...     []  B08GPJ1MSN   \n",
       "1  I’ve ordered three bows so far. Have not been ...     []  B084TWHS7W   \n",
       "2  As pictured. Used a frame from the dollar stor...     []  B07V3NRQC4   \n",
       "\n",
       "  parent_asin                       user_id      timestamp  helpful_vote  \\\n",
       "0  B08GPJ1MSN  AF7OANMNHQJC3PD4HRPX2FATECPA  1621607495111             1   \n",
       "1  B084TWHS7W  AGMJ3EMDVL6OWBJF7CA5RGJLXN5A  1587762946965             0   \n",
       "2  B07V3NRQC4  AEYORY2AVPMCPDV57CE337YU5LXA  1591448951297             0   \n",
       "\n",
       "   verified_purchase  \n",
       "0               True  \n",
       "1               True  \n",
       "2               True  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Handmade Metadata DataFrame Info ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   main_category    10000 non-null  object \n",
      " 1   title            10000 non-null  object \n",
      " 2   average_rating   10000 non-null  float64\n",
      " 3   rating_number    10000 non-null  int64  \n",
      " 4   features         10000 non-null  object \n",
      " 5   description      10000 non-null  object \n",
      " 6   price            6514 non-null   float64\n",
      " 7   images           10000 non-null  object \n",
      " 8   videos           10000 non-null  object \n",
      " 9   store            9930 non-null   object \n",
      " 10  categories       10000 non-null  object \n",
      " 11  details          10000 non-null  object \n",
      " 12  parent_asin      10000 non-null  object \n",
      " 13  bought_together  0 non-null      object \n",
      "dtypes: float64(2), int64(1), object(11)\n",
      "memory usage: 1.1+ MB\n",
      "\n",
      "--- First 3 rows of Handmade Metadata ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_category</th>\n",
       "      <th>title</th>\n",
       "      <th>average_rating</th>\n",
       "      <th>rating_number</th>\n",
       "      <th>features</th>\n",
       "      <th>description</th>\n",
       "      <th>price</th>\n",
       "      <th>images</th>\n",
       "      <th>videos</th>\n",
       "      <th>store</th>\n",
       "      <th>categories</th>\n",
       "      <th>details</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>bought_together</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Handmade</td>\n",
       "      <td>Daisy Keychain Wristlet Gray Fabric Key fob La...</td>\n",
       "      <td>4.5</td>\n",
       "      <td>12</td>\n",
       "      <td>[High Quality Fabrics, Antique Brass Metallic ...</td>\n",
       "      <td>[This charming Daisy Fabric Keychain wristlet ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Generic</td>\n",
       "      <td>[Handmade Products, Clothing, Shoes &amp; Accessor...</td>\n",
       "      <td>{'Package Dimensions': '8 x 4 x 0.85 inches; 0...</td>\n",
       "      <td>B07NTK7T5P</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Handmade</td>\n",
       "      <td>Anemone Jewelry Beauteous November Birthstone ...</td>\n",
       "      <td>4.1</td>\n",
       "      <td>10</td>\n",
       "      <td>[Stunning gemstone and detailed design, Bands ...</td>\n",
       "      <td>[Anemone brings this November birthstone ring ...</td>\n",
       "      <td>69.0</td>\n",
       "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Anemone Jewelry</td>\n",
       "      <td>[Handmade Products, Jewelry, Rings, Statement]</td>\n",
       "      <td>{'Department': 'womens', 'Date First Available...</td>\n",
       "      <td>B0751M85FV</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Handmade</td>\n",
       "      <td>Silver Triangle Earrings with Chevron Pattern</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1</td>\n",
       "      <td>[]</td>\n",
       "      <td>[These large silver triangles are stamped with...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>[{'thumb': 'https://m.media-amazon.com/images/...</td>\n",
       "      <td>[]</td>\n",
       "      <td>Zoë Noelle Designs</td>\n",
       "      <td>[Handmade Products, Jewelry, Earrings, Drop &amp; ...</td>\n",
       "      <td>{'Department': 'Women', 'Date First Available'...</td>\n",
       "      <td>B01HYNE114</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  main_category                                              title  \\\n",
       "0      Handmade  Daisy Keychain Wristlet Gray Fabric Key fob La...   \n",
       "1      Handmade  Anemone Jewelry Beauteous November Birthstone ...   \n",
       "2      Handmade      Silver Triangle Earrings with Chevron Pattern   \n",
       "\n",
       "   average_rating  rating_number  \\\n",
       "0             4.5             12   \n",
       "1             4.1             10   \n",
       "2             5.0              1   \n",
       "\n",
       "                                            features  \\\n",
       "0  [High Quality Fabrics, Antique Brass Metallic ...   \n",
       "1  [Stunning gemstone and detailed design, Bands ...   \n",
       "2                                                 []   \n",
       "\n",
       "                                         description  price  \\\n",
       "0  [This charming Daisy Fabric Keychain wristlet ...    NaN   \n",
       "1  [Anemone brings this November birthstone ring ...   69.0   \n",
       "2  [These large silver triangles are stamped with...    NaN   \n",
       "\n",
       "                                              images videos  \\\n",
       "0  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
       "1  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
       "2  [{'thumb': 'https://m.media-amazon.com/images/...     []   \n",
       "\n",
       "                store                                         categories  \\\n",
       "0             Generic  [Handmade Products, Clothing, Shoes & Accessor...   \n",
       "1     Anemone Jewelry     [Handmade Products, Jewelry, Rings, Statement]   \n",
       "2  Zoë Noelle Designs  [Handmade Products, Jewelry, Earrings, Drop & ...   \n",
       "\n",
       "                                             details parent_asin  \\\n",
       "0  {'Package Dimensions': '8 x 4 x 0.85 inches; 0...  B07NTK7T5P   \n",
       "1  {'Department': 'womens', 'Date First Available...  B0751M85FV   \n",
       "2  {'Department': 'Women', 'Date First Available'...  B01HYNE114   \n",
       "\n",
       "  bought_together  \n",
       "0            None  \n",
       "1            None  \n",
       "2            None  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gzip\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ---- 1. 定义数据加载函数 ----\n",
    "# 这个函数可以逐行读取压缩的jsonl文件，避免一次性加载到内存中导致崩溃\n",
    "def load_data(file_path, limit=None):\n",
    "    data = []\n",
    "    with gzip.open(file_path, 'rt', encoding='utf-8') as f:\n",
    "        for i, line in enumerate(tqdm(f, desc=f\"Loading {file_path.split('/')[-1]}\")):\n",
    "            if limit and i >= limit:\n",
    "                break\n",
    "            data.append(json.loads(line))\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# ---- 2. 设置文件路径 ----\n",
    "# 请确保这个路径与您的项目结构一致\n",
    "RAW_DATA_PATH = '../data/raw/'\n",
    "\n",
    "# Handmade 品类的文件路径\n",
    "handmade_reviews_path = RAW_DATA_PATH + 'Handmade_Products.jsonl.gz'\n",
    "handmade_meta_path = RAW_DATA_PATH + 'meta_Handmade_Products.jsonl.gz'\n",
    "\n",
    "# Health & Personal Care 品类的文件路径\n",
    "health_reviews_path = RAW_DATA_PATH + 'Health_and_Personal_Care.jsonl.gz'\n",
    "health_meta_path = RAW_DATA_PATH + 'meta_Health_and_Personal_Care.jsonl.gz'\n",
    "\n",
    "\n",
    "# ---- 3. 加载 Handmade 数据进行初步探索 ----\n",
    "# 为了快速测试，我们先只加载前10000条记录。如果运行顺利，可以去掉 limit=10000 参数来加载全部数据。\n",
    "print(\"--- Loading Handmade Reviews ---\")\n",
    "df_reviews_handmade = load_data(handmade_reviews_path, limit=10000)\n",
    "\n",
    "print(\"\\n--- Loading Handmade Metadata ---\")\n",
    "df_meta_handmade = load_data(handmade_meta_path, limit=10000)\n",
    "\n",
    "\n",
    "# ---- 4. 显示加载后的数据信息 ----\n",
    "print(\"\\n--- Handmade Reviews DataFrame Info ---\")\n",
    "df_reviews_handmade.info()\n",
    "print(\"\\n--- First 3 rows of Handmade Reviews ---\")\n",
    "display(df_reviews_handmade.head(3))\n",
    "\n",
    "print(\"\\n--- Handmade Metadata DataFrame Info ---\")\n",
    "df_meta_handmade.info()\n",
    "print(\"\\n--- First 3 rows of Handmade Metadata ---\")\n",
    "display(df_meta_handmade.head(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270389fe-3e3a-40dd-b656-f129510036dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Merged DataFrame for Handmade ---\n",
      "Original reviews count: 10000\n",
      "Merged count: 1021\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1021 entries, 0 to 1020\n",
      "Data columns (total 7 columns):\n",
      " #   Column       Non-Null Count  Dtype \n",
      "---  ------       --------------  ----- \n",
      " 0   user_id      1021 non-null   object\n",
      " 1   parent_asin  1021 non-null   object\n",
      " 2   text         1021 non-null   object\n",
      " 3   timestamp    1021 non-null   int64 \n",
      " 4   title        1021 non-null   object\n",
      " 5   description  1021 non-null   object\n",
      " 6   images       1021 non-null   object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 63.8+ KB\n",
      "\n",
      "--- Final Processed DataFrame for Handmade (Top 5 rows) ---\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>image_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AF2FTNKCY6XY67BKBUO4BNJRZ4XQ</td>\n",
       "      <td>B09GK2JJDZ</td>\n",
       "      <td>1669860506507</td>\n",
       "      <td>Cats Dogs ID Tags Personalized Lovely Symbols ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61pFszChat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AHPBIP5JNVD4ZDTULYEAAX2PBDGQ</td>\n",
       "      <td>B09GK2JJDZ</td>\n",
       "      <td>1658635895538</td>\n",
       "      <td>Cats Dogs ID Tags Personalized Lovely Symbols ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61pFszChat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AEUKSETY42JHTLQY734DRPDGMSXA</td>\n",
       "      <td>B09GK2JJDZ</td>\n",
       "      <td>1663898449664</td>\n",
       "      <td>Cats Dogs ID Tags Personalized Lovely Symbols ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61pFszChat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AEAE2ZYPWPDUJHAAMGQIL7LNVTPA</td>\n",
       "      <td>B09GK2JJDZ</td>\n",
       "      <td>1677866085425</td>\n",
       "      <td>Cats Dogs ID Tags Personalized Lovely Symbols ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61pFszChat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AGQOAL23M4GPIYK2WKSEMW3Q27EQ</td>\n",
       "      <td>B09GK2JJDZ</td>\n",
       "      <td>1644892809092</td>\n",
       "      <td>Cats Dogs ID Tags Personalized Lovely Symbols ...</td>\n",
       "      <td>https://m.media-amazon.com/images/I/61pFszChat...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id parent_asin      timestamp  \\\n",
       "0  AF2FTNKCY6XY67BKBUO4BNJRZ4XQ  B09GK2JJDZ  1669860506507   \n",
       "1  AHPBIP5JNVD4ZDTULYEAAX2PBDGQ  B09GK2JJDZ  1658635895538   \n",
       "2  AEUKSETY42JHTLQY734DRPDGMSXA  B09GK2JJDZ  1663898449664   \n",
       "3  AEAE2ZYPWPDUJHAAMGQIL7LNVTPA  B09GK2JJDZ  1677866085425   \n",
       "4  AGQOAL23M4GPIYK2WKSEMW3Q27EQ  B09GK2JJDZ  1644892809092   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  Cats Dogs ID Tags Personalized Lovely Symbols ...   \n",
       "1  Cats Dogs ID Tags Personalized Lovely Symbols ...   \n",
       "2  Cats Dogs ID Tags Personalized Lovely Symbols ...   \n",
       "3  Cats Dogs ID Tags Personalized Lovely Symbols ...   \n",
       "4  Cats Dogs ID Tags Personalized Lovely Symbols ...   \n",
       "\n",
       "                                           image_url  \n",
       "0  https://m.media-amazon.com/images/I/61pFszChat...  \n",
       "1  https://m.media-amazon.com/images/I/61pFszChat...  \n",
       "2  https://m.media-amazon.com/images/I/61pFszChat...  \n",
       "3  https://m.media-amazon.com/images/I/61pFszChat...  \n",
       "4  https://m.media-amazon.com/images/I/61pFszChat...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Total clean records for Handmade: 1021\n"
     ]
    }
   ],
   "source": [
    "# ---- 5. 筛选核心列 ----\n",
    "# 我们不需要所有列，只选择对模型有用的，可以节省大量内存\n",
    "cols_reviews = ['user_id', 'parent_asin', 'text', 'timestamp']\n",
    "cols_meta = ['parent_asin', 'title', 'description', 'images']\n",
    "\n",
    "df_reviews_handmade_slim = df_reviews_handmade[cols_reviews]\n",
    "df_meta_handmade_slim = df_meta_handmade[cols_meta]\n",
    "\n",
    "# ---- 6. 合并评论和元数据 ----\n",
    "# 使用 'inner' 合并，确保我们只保留同时拥有评论和元数据的商品交互记录\n",
    "df_handmade_merged = pd.merge(\n",
    "    df_reviews_handmade_slim,\n",
    "    df_meta_handmade_slim,\n",
    "    on='parent_asin',\n",
    "    how='inner'\n",
    ")\n",
    "\n",
    "print(f\"--- Merged DataFrame for Handmade ---\")\n",
    "print(f\"Original reviews count: {len(df_reviews_handmade_slim)}\")\n",
    "print(f\"Merged count: {len(df_handmade_merged)}\")\n",
    "df_handmade_merged.info()\n",
    "\n",
    "\n",
    "# ---- 7. 数据清洗与特征提取 ----\n",
    "\n",
    "# 7.1) 定义一个函数来安全地提取高清图片URL\n",
    "def extract_image_url(image_list):\n",
    "    if not isinstance(image_list, list) or len(image_list) == 0:\n",
    "        return None\n",
    "    for img in image_list:\n",
    "        if isinstance(img, dict) and img.get('hi_res'):\n",
    "            return img['hi_res']\n",
    "    if isinstance(image_list[0], dict) and image_list[0].get('large'):\n",
    "        return image_list[0]['large']\n",
    "    return None\n",
    "\n",
    "# 7.2) 应用函数，创建新的 'image_url' 列\n",
    "df_handmade_merged['image_url'] = df_handmade_merged['images'].apply(extract_image_url)\n",
    "\n",
    "# 【--- 错误修正处 ---】\n",
    "# 在合并文本前，将 description 列中的列表转换为字符串\n",
    "def join_if_list(entry):\n",
    "    if isinstance(entry, list):\n",
    "        return ' '.join(str(item) for item in entry) # 将列表元素用空格连接成一个字符串\n",
    "    return entry\n",
    "\n",
    "# 将这个转换函数应用到 description 列\n",
    "df_handmade_merged['description'] = df_handmade_merged['description'].apply(join_if_list)\n",
    "# 【--- 修正结束 ---】\n",
    "\n",
    "\n",
    "# 7.3) 组合文本特征 (标题 + 描述 + 评论)\n",
    "# fillna('') 确保即使某部分文本缺失，也不会导致错误\n",
    "df_handmade_merged['combined_text'] = (\n",
    "    df_handmade_merged['title'].fillna('') + ' . ' +\n",
    "    df_handmade_merged['description'].fillna('') + ' . ' + # 现在这一步是安全的\n",
    "    df_handmade_merged['text'].fillna('')\n",
    ")\n",
    "\n",
    "# 7.4) 移除空值和不再需要的列\n",
    "# 确保所有核心信息都存在，特别是 image_url\n",
    "df_handmade_final = df_handmade_merged.dropna(subset=['user_id', 'parent_asin', 'timestamp', 'image_url', 'combined_text'])\n",
    "\n",
    "# 只保留最终需要的列\n",
    "final_cols = ['user_id', 'parent_asin', 'timestamp', 'combined_text', 'image_url']\n",
    "df_handmade_final = df_handmade_final[final_cols]\n",
    "\n",
    "\n",
    "# ---- 8. 显示最终处理好的数据 ----\n",
    "print(\"\\n--- Final Processed DataFrame for Handmade (Top 5 rows) ---\")\n",
    "display(df_handmade_final.head())\n",
    "\n",
    "print(f\"\\nTotal clean records for Handmade: {len(df_handmade_final)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "52545e6b-e722-40d5-b7fa-306424eac1aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Processing category: Handmade_Products.jsonl.gz ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Handmade_Products.jsonl.gz: 10000it [00:00, 66793.92it/s]\n",
      "Loading meta_Handmade_Products.jsonl.gz: 10000it [00:00, 22048.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Found 1021 clean records.\n",
      "\n",
      "--- Processing category: Health_and_Personal_Care.jsonl.gz ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading Health_and_Personal_Care.jsonl.gz: 10000it [00:00, 30797.90it/s]\n",
      "Loading meta_Health_and_Personal_Care.jsonl.gz: 10000it [00:00, 23895.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished processing. Found 2546 clean records.\n",
      "\n",
      "--- Combined DataFrame ---\n",
      "Total records from all categories: 3567\n",
      "\n",
      "--- Building User Sequences ---\n",
      "\n",
      "--- Final Sequential DataFrame ---\n",
      "Total number of users with sequences: 238\n",
      "Each row represents a user, with their historical interactions aggregated into lists.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>parent_asin</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>image_url</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>sequence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AE2YT5NODO5H7VNHTO6CYQAE4VQA</td>\n",
       "      <td>[B0C5BPS25X, B0C5BPS25X]</td>\n",
       "      <td>[Cascade Complete Powder Dishwasher Detergent ...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/71Ryg2c2J...</td>\n",
       "      <td>[1490230355000, 1490230355000]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AE3FC3VW5FA434GIZ22WTTOFTH5A</td>\n",
       "      <td>[B083T9VD7J, B01M4NB3OJ]</td>\n",
       "      <td>[Connoisseurs Silver Jewelry Cleaner with Clea...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/81gfjJ2+n...</td>\n",
       "      <td>[1595800056992, 1614091185943]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AE3KLVXGZPANXE5XLXYKHTVAZ3FQ</td>\n",
       "      <td>[B075J1D3QD, B07XVVVB8W, B08M5BX9VK, B08R9DFCG...</td>\n",
       "      <td>[7 pcs Ear Picks Earwax Removal Care Kit, Ear ...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/610t4QvtQ...</td>\n",
       "      <td>[1511899508596, 1572203039766, 1613918829108, ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AE3VBP5V3YQVBMHQLV5C3AX4JBTA</td>\n",
       "      <td>[B07D6NVJCX, B0759GBX47]</td>\n",
       "      <td>[Navya Craft Labradorite Round Silver Ring 925...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/61B5KngPW...</td>\n",
       "      <td>[1599573787239, 1600900435210]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AE4JZ7OUABFFH2GV7Z7DJVOICS7A</td>\n",
       "      <td>[B0C1HHXQ94, B00RKNVZFE]</td>\n",
       "      <td>[ASUTRA Natural &amp; Organic Yoga Mat Cleaner (Mi...</td>\n",
       "      <td>[https://m.media-amazon.com/images/I/81qEnhizz...</td>\n",
       "      <td>[1522340932338, 1536925603760]</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        user_id  \\\n",
       "0  AE2YT5NODO5H7VNHTO6CYQAE4VQA   \n",
       "1  AE3FC3VW5FA434GIZ22WTTOFTH5A   \n",
       "2  AE3KLVXGZPANXE5XLXYKHTVAZ3FQ   \n",
       "3  AE3VBP5V3YQVBMHQLV5C3AX4JBTA   \n",
       "4  AE4JZ7OUABFFH2GV7Z7DJVOICS7A   \n",
       "\n",
       "                                         parent_asin  \\\n",
       "0                           [B0C5BPS25X, B0C5BPS25X]   \n",
       "1                           [B083T9VD7J, B01M4NB3OJ]   \n",
       "2  [B075J1D3QD, B07XVVVB8W, B08M5BX9VK, B08R9DFCG...   \n",
       "3                           [B07D6NVJCX, B0759GBX47]   \n",
       "4                           [B0C1HHXQ94, B00RKNVZFE]   \n",
       "\n",
       "                                       combined_text  \\\n",
       "0  [Cascade Complete Powder Dishwasher Detergent ...   \n",
       "1  [Connoisseurs Silver Jewelry Cleaner with Clea...   \n",
       "2  [7 pcs Ear Picks Earwax Removal Care Kit, Ear ...   \n",
       "3  [Navya Craft Labradorite Round Silver Ring 925...   \n",
       "4  [ASUTRA Natural & Organic Yoga Mat Cleaner (Mi...   \n",
       "\n",
       "                                           image_url  \\\n",
       "0  [https://m.media-amazon.com/images/I/71Ryg2c2J...   \n",
       "1  [https://m.media-amazon.com/images/I/81gfjJ2+n...   \n",
       "2  [https://m.media-amazon.com/images/I/610t4QvtQ...   \n",
       "3  [https://m.media-amazon.com/images/I/61B5KngPW...   \n",
       "4  [https://m.media-amazon.com/images/I/81qEnhizz...   \n",
       "\n",
       "                                           timestamp  sequence_length  \n",
       "0                     [1490230355000, 1490230355000]                2  \n",
       "1                     [1595800056992, 1614091185943]                2  \n",
       "2  [1511899508596, 1572203039766, 1613918829108, ...                5  \n",
       "3                     [1599573787239, 1600900435210]                2  \n",
       "4                     [1522340932338, 1536925603760]                2  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Successfully saved processed sequential data to: ../data/processed/sequential_data_sample.pkl\n"
     ]
    }
   ],
   "source": [
    "# ---- 9. 将处理流程封装成一个函数 ----\n",
    "def process_category(review_path, meta_path, limit=None):\n",
    "    \"\"\"加载、合并和清洗指定品类的数据\"\"\"\n",
    "    print(f\"\\n--- Processing category: {review_path.split('/')[-1]} ---\")\n",
    "    \n",
    "    # 加载数据\n",
    "    df_reviews = load_data(review_path, limit=limit)\n",
    "    df_meta = load_data(meta_path, limit=limit)\n",
    "    \n",
    "    # 筛选核心列\n",
    "    cols_reviews = ['user_id', 'parent_asin', 'text', 'timestamp']\n",
    "    cols_meta = ['parent_asin', 'title', 'description', 'images']\n",
    "    df_reviews_slim = df_reviews[cols_reviews]\n",
    "    df_meta_slim = df_meta[cols_meta]\n",
    "    \n",
    "    # 合并\n",
    "    df_merged = pd.merge(df_reviews_slim, df_meta_slim, on='parent_asin', how='inner')\n",
    "    \n",
    "    # 清洗与特征提取\n",
    "    df_merged['image_url'] = df_merged['images'].apply(extract_image_url)\n",
    "    \n",
    "    def join_if_list(entry):\n",
    "        if isinstance(entry, list):\n",
    "            return ' '.join(str(item) for item in entry)\n",
    "        return entry\n",
    "    df_merged['description'] = df_merged['description'].apply(join_if_list)\n",
    "    \n",
    "    df_merged['combined_text'] = (\n",
    "        df_merged['title'].fillna('') + ' . ' +\n",
    "        df_merged['description'].fillna('') + ' . ' +\n",
    "        df_merged['text'].fillna('')\n",
    "    )\n",
    "    \n",
    "    final_cols = ['user_id', 'parent_asin', 'timestamp', 'combined_text', 'image_url']\n",
    "    df_final = df_merged.dropna(subset=final_cols)[final_cols]\n",
    "    \n",
    "    print(f\"Finished processing. Found {len(df_final)} clean records.\")\n",
    "    return df_final\n",
    "\n",
    "# ---- 10. 处理所有品类并合并 ----\n",
    "# 注意：为了节省时间和内存，我们继续使用 limit=10000。\n",
    "# 在您准备好进行完整训练时，可以移除 limit 参数。\n",
    "df_handmade_final = process_category(handmade_reviews_path, handmade_meta_path, limit=10000)\n",
    "df_health_final = process_category(health_reviews_path, health_meta_path, limit=10000)\n",
    "\n",
    "# 合并两个品类的 DataFrame\n",
    "df_all = pd.concat([df_handmade_final, df_health_final], ignore_index=True)\n",
    "print(f\"\\n--- Combined DataFrame ---\")\n",
    "print(f\"Total records from all categories: {len(df_all)}\")\n",
    "\n",
    "\n",
    "# ---- 11. 构建用户行为序列 ----\n",
    "print(\"\\n--- Building User Sequences ---\")\n",
    "\n",
    "# 11.1) 按用户ID和时间戳排序，这是构建序列最关键的一步\n",
    "df_all_sorted = df_all.sort_values(by=['user_id', 'timestamp'])\n",
    "\n",
    "# 11.2) 按 user_id 分组，并将每个用户的交互信息聚合为列表\n",
    "df_sequences = df_all_sorted.groupby('user_id').agg({\n",
    "    'parent_asin': list,\n",
    "    'combined_text': list,\n",
    "    'image_url': list,\n",
    "    'timestamp': list\n",
    "}).reset_index()\n",
    "\n",
    "# 11.3) 筛选掉只有一个交互的用户（无法形成序列进行预测）\n",
    "df_sequences['sequence_length'] = df_sequences['parent_asin'].apply(len)\n",
    "df_sequences = df_sequences[df_sequences['sequence_length'] > 1].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# ---- 12. 显示最终的序列化数据 ----\n",
    "print(f\"\\n--- Final Sequential DataFrame ---\")\n",
    "print(f\"Total number of users with sequences: {len(df_sequences)}\")\n",
    "print(\"Each row represents a user, with their historical interactions aggregated into lists.\")\n",
    "display(df_sequences.head())\n",
    "\n",
    "\n",
    "# ---- 13. 保存处理好的数据 ----\n",
    "# 使用 pickle 格式可以完整地保存 DataFrame 的结构，包括列表\n",
    "PROCESSED_DATA_PATH = '../data/processed/'\n",
    "output_filename = PROCESSED_DATA_PATH + 'sequential_data_sample.pkl'\n",
    "df_sequences.to_pickle(output_filename)\n",
    "\n",
    "print(f\"\\nSuccessfully saved processed sequential data to: {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f0a28482-7599-4bca-86fa-458f0743eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Initializing Dataset ---\n",
      "Loading data from: ../data/processed/sequential_data_sample.pkl\n",
      "Data loaded. Total users: 238\n",
      "\n",
      "Total users in dataset: 238\n",
      "\n",
      "--- Testing __getitem__ for the first user (index 0) ---\n",
      "\n",
      "- input_item_ids (length: 50):\n",
      "  First 5: ['<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "  Last 5:  ['<PAD>', '<PAD>', '<PAD>', '<PAD>', 'B0C5BPS25X']\n",
      "\n",
      "- input_texts (length: 50):\n",
      "  First 5: ['', '', '', '', '']\n",
      "  Last 5:  ['', '', '', '', 'Cascade Complete Powder Dishwasher Detergent - Fresh Scent - 75oz (Pack of 2) .  . I received Cascade Complete as listed in the product description.  Good product.']\n",
      "\n",
      "- input_images (length: 50):\n",
      "  First 5: ['', '', '', '', '']\n",
      "  Last 5:  ['', '', '', '', 'https://m.media-amazon.com/images/I/71Ryg2c2JmL._AC_SL1280_.jpg']\n",
      "\n",
      "- target_item_id:\n",
      "  Value: B0C5BPS25X\n",
      "\n",
      "- target_text:\n",
      "  Value: Cascade Complete Powder Dishwasher Detergent - Fresh Scent - 75oz (Pack of 2) .  . I received Cascade Complete as listed in the product description.  Good product.\n",
      "\n",
      "- target_image:\n",
      "  Value: https://m.media-amazon.com/images/I/71Ryg2c2JmL._AC_SL1280_.jpg\n",
      "\n",
      "--- Testing DataLoader ---\n",
      "Successfully created a batch of size 2.\n",
      "Keys in the batch: dict_keys(['input_item_ids', 'input_texts', 'input_images', 'target_item_id', 'target_text', 'target_image'])\n",
      "Shape of input_texts in the batch: 50 users x 2 items\n"
     ]
    }
   ],
   "source": [
    "# ---- 测试我们自定义的 Dataset 和 DataLoader ----\n",
    "\n",
    "# 由于 data_loader.py 在 src 目录下，我们需要将 src 目录添加到系统路径中\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "# 从 data_loader.py 文件中导入 RecSysDataset 类\n",
    "from data_loader import RecSysDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# 1. 创建 Dataset 实例\n",
    "print(\"--- Initializing Dataset ---\")\n",
    "PROCESSED_DATA_PATH = '../data/processed/sequential_data_sample.pkl'\n",
    "dataset = RecSysDataset(data_path=PROCESSED_DATA_PATH, max_seq_len=50)\n",
    "\n",
    "# 2. 验证 __len__ 方法\n",
    "print(f\"\\nTotal users in dataset: {len(dataset)}\")\n",
    "\n",
    "# 3. 验证 __getitem__ 方法\n",
    "print(\"\\n--- Testing __getitem__ for the first user (index 0) ---\")\n",
    "sample_user_data = dataset[0]\n",
    "\n",
    "# 打印样本数据的结构和内容\n",
    "for key, value in sample_user_data.items():\n",
    "    # 为了美观，只打印序列的前5个和后5个元素\n",
    "    if isinstance(value, list):\n",
    "        print(f\"\\n- {key} (length: {len(value)}):\")\n",
    "        if len(value) > 10:\n",
    "            print(f\"  First 5: {value[:5]}\")\n",
    "            print(f\"  Last 5:  {value[-5:]}\")\n",
    "        else:\n",
    "            print(f\"  Value: {value}\")\n",
    "    else:\n",
    "        print(f\"\\n- {key}:\\n  Value: {value}\")\n",
    "\n",
    "# 4. 测试 DataLoader\n",
    "# DataLoader 会自动将多条数据打包成一个批次(batch)\n",
    "print(\"\\n--- Testing DataLoader ---\")\n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "print(\"Successfully created a batch of size 2.\")\n",
    "print(\"Keys in the batch:\", first_batch.keys())\n",
    "print(\"Shape of input_texts in the batch:\", len(first_batch['input_texts']), \"users x\", len(first_batch['input_texts'][0]), \"items\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a918b42a-e13b-48fb-b2c3-ddd68b980600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using device: cuda ---\n",
      "Loading CLIP model and processor...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34ba57e5e9a148c3a56cce2caa377cf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/316 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ee631f7963d42abbc12a8699d4797a6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/592 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "369c81c425394a228a2c4dd4110fe11c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c7bd8a1723164ada9852a5c25565a279",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "472ea409db5144feba0d8add4254dfe9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6cd16887ead4af2ab648e8c2e2c3085",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/389 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d033baeec0d24f04bf7bf94bc2808c26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d636478df3d54cb1a8e759acbc23be6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "pytorch_model.bin:   0%|          | 0.00/605M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CLIP model loaded successfully.\n",
      "\n",
      "--- Testing Encoder with a batch of size: 2 ---\n",
      "Sample Text: UCARI Intolerance & Food Sensitivity Test Kit for Adults & Kids | 1500+ Food, En...\n",
      "Sample Image URL: https://m.media-amazon.com/images/I/61edIYIp8UL._AC_SL1500_.jpg\n",
      "\n",
      "--- Verifying Output ---\n",
      "Shape of the output tensor: torch.Size([2, 512])\n",
      "Data type of the output tensor: torch.float32\n",
      "Output tensor is on device: cuda:0\n",
      "Norm of the first output vector: 1.0000 (should be close to 1.0)\n"
     ]
    }
   ],
   "source": [
    "# ---- 测试我们自定义的 MultimodalEncoder ----\n",
    "\n",
    "# 确保 src 目录在系统路径中\n",
    "import sys\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "# 从 models.py 文件中导入 MultimodalEncoder 类\n",
    "from models import MultimodalEncoder\n",
    "import torch\n",
    "\n",
    "# 1. 确定运行设备\n",
    "# 检查服务器是否有可用的CUDA GPU，如果有，就使用GPU，否则使用CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--- Using device: {device} ---\")\n",
    "\n",
    "\n",
    "# 2. 初始化多模态编码器\n",
    "# 将模型实例化的同时，直接移动到我们确定的设备上\n",
    "try:\n",
    "    encoder = MultimodalEncoder(device=device)\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing MultimodalEncoder: {e}\")\n",
    "    # 如果出错，可能是网络问题或Hugging Face Hub访问问题，这里先假设能成功\n",
    "\n",
    "\n",
    "# 3. 从 DataLoader 中获取一个真实的数据批次\n",
    "# 我们之前已经创建了 dataloader 实例\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# 我们只需要目标物品（target item）的文本和图片URL来测试编码器\n",
    "sample_texts = list(first_batch['target_text'])\n",
    "sample_image_urls = list(first_batch['target_image'])\n",
    "\n",
    "print(f\"\\n--- Testing Encoder with a batch of size: {len(sample_texts)} ---\")\n",
    "print(\"Sample Text:\", sample_texts[0][:80] + \"...\") # 打印第一个文本的前80个字符\n",
    "print(\"Sample Image URL:\", sample_image_urls[0])\n",
    "\n",
    "\n",
    "# 4. 执行前向传播\n",
    "# 将数据送入编码器，得到输出的嵌入向量\n",
    "# 使用 torch.no_grad() 是一个好习惯，因为我们只是在测试（推理），不需要计算梯度\n",
    "with torch.no_grad():\n",
    "    # 将编码器设置为评估模式\n",
    "    encoder.eval() \n",
    "    \n",
    "    # 得到输出\n",
    "    output_embeddings = encoder(texts=sample_texts, image_urls=sample_image_urls)\n",
    "\n",
    "\n",
    "# 5. 验证输出\n",
    "print(\"\\n--- Verifying Output ---\")\n",
    "print(f\"Shape of the output tensor: {output_embeddings.shape}\")\n",
    "print(f\"Data type of the output tensor: {output_embeddings.dtype}\")\n",
    "print(f\"Output tensor is on device: {output_embeddings.device}\")\n",
    "\n",
    "# 检查输出向量的范数（长度），因为我们代码里做了L2归一化，所以它的范数应该约等于1\n",
    "# 我们只检查第一个向量\n",
    "first_vector_norm = torch.linalg.norm(output_embeddings[0])\n",
    "print(f\"Norm of the first output vector: {first_vector_norm.item():.4f} (should be close to 1.0)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "00a1f2d9-6575-458e-abcd-64d682567e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Using device: cuda ---\n",
      "\n",
      "--- Initializing the full GenerativeRecSysModel ---\n",
      "\n",
      "--- Initializing Item ID Embeddings ---\n",
      "Item ID embedding layer created for 415 unique items.\n",
      "\n",
      "Corrected batch shape: 2 users x 50 sequence length\n",
      "\n",
      "--- Performing a forward pass through the full model ---\n",
      "\n",
      "--- Verifying Final Output ---\n",
      "Shape of the final user interest vector: torch.Size([2, 512])\n",
      "Output vector is on device: cuda:0\n",
      "Does the output contain NaN values? False\n"
     ]
    }
   ],
   "source": [
    "# ---- 测试完整的 GenerativeRecSysModel (修正版) ----\n",
    "import pandas as pd\n",
    "import torch\n",
    "import importlib\n",
    "\n",
    "# 确保 src 目录在系统路径中并强制重载\n",
    "import sys\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "import models\n",
    "importlib.reload(models)\n",
    "from models import GenerativeRecSysModel\n",
    "\n",
    "# 1. 确定运行设备\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"--- Using device: {device} ---\")\n",
    "\n",
    "# 2. 初始化完整的模型\n",
    "print(\"\\n--- Initializing the full GenerativeRecSysModel ---\")\n",
    "model = GenerativeRecSysModel(embed_dim=512, nhead=8, num_layers=3, device=device)\n",
    "model.to(device)\n",
    "\n",
    "# 3. 初始化模型的 Item ID 嵌入层\n",
    "print(\"\\n--- Initializing Item ID Embeddings ---\")\n",
    "full_data_df = pd.read_pickle('../data/processed/sequential_data_sample.pkl')\n",
    "all_unique_item_ids = full_data_df['parent_asin'].explode().unique()\n",
    "model.create_item_embeddings(all_unique_item_ids)\n",
    "print(f\"Item ID embedding layer created for {len(all_unique_item_ids)} unique items.\")\n",
    "\n",
    "# 4. 从 DataLoader 中获取一个真实的数据批次\n",
    "first_batch = next(iter(dataloader))\n",
    "\n",
    "# 【--- 错误修正处 ---】\n",
    "# DataLoader 输出的批次是 (seq_len, batch_size)，我们需要将其转置为 (batch_size, seq_len)\n",
    "# 使用 zip(*) 可以非常优雅地实现列表的转置\n",
    "batch_input_ids = list(zip(*first_batch['input_item_ids']))\n",
    "batch_input_texts = list(zip(*first_batch['input_texts']))\n",
    "batch_input_images = list(zip(*first_batch['input_images']))\n",
    "print(f\"\\nCorrected batch shape: {len(batch_input_ids)} users x {len(batch_input_ids[0])} sequence length\")\n",
    "# 【--- 修正结束 ---】\n",
    "\n",
    "# 5. 执行完整模型的前向传播\n",
    "print(\"\\n--- Performing a forward pass through the full model ---\")\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    user_interest_vector = model(\n",
    "        input_item_ids=batch_input_ids,\n",
    "        input_texts=batch_input_texts,\n",
    "        input_images=batch_input_images\n",
    "    )\n",
    "\n",
    "# 6. 验证最终输出\n",
    "print(\"\\n--- Verifying Final Output ---\")\n",
    "print(f\"Shape of the final user interest vector: {user_interest_vector.shape}\")\n",
    "print(f\"Output vector is on device: {user_interest_vector.device}\")\n",
    "has_nan = torch.isnan(user_interest_vector).any()\n",
    "print(f\"Does the output contain NaN values? {has_nan.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea9e368c-7ce3-4bce-a549-71191b36649d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Found a valid and meaningful user history for testing ---\n",
      "\n",
      "=== Please copy the following content into test_user_history.txt ===\n",
      "\n",
      "{\"parent_asin\": \"B083T9VD7J\", \"combined_text\": \"Connoisseurs Silver Jewelry Cleaner with Cleaning Basket and Polishing Cloth 8 oz. .  . I had a cross made of silver and it was completely black from tarnishing, I follow the directions and dip it in the solution for just a few seconds when It came out I wiped it and wonderful. Great product highly recommend .\", \"image_url\": \"https://m.media-amazon.com/images/I/81gfjJ2+n3L._AC_SL1500_.jpg\"}\n",
      "{\"parent_asin\": \"B01M4NB3OJ\", \"combined_text\": \"Microwave Dish Cozies, Set of 3, 1 Small Bowl Cozy, 1 Medium Bowl Cozy, and 1 Dinner Plate Cozy, Kitchen Motif . Microwave cozy set includes 3 dish cozies. 1 small bowl cozy (About 6.5\\\" square, pictured with 5\\u201d diameter bowl and a mug), 1 medium bowl cozy (About 8\\\" square, pictured with 6\\u201d diameter bowl), 1 dinner plate cozy (About 10\\\" square, pictured with 10.5\\u201d plate and 8\\u201d casserole dish). . Very good quality, no more hot bowls or plates.\", \"image_url\": \"https://m.media-amazon.com/images/I/81S+krTq3sL._SL1500_.jpg\"}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 加载我们处理好的序列数据\n",
    "df_sequences = pd.read_pickle('../data/processed/sequential_data_sample.pkl')\n",
    "\n",
    "# --- 智能寻找一个有效的、非重复的测试历史 ---\n",
    "found_user = None\n",
    "for index, user in df_sequences.iterrows():\n",
    "    # 检查该用户的购买历史中，是否包含至少2个【不重复】的商品ID\n",
    "    if len(set(user['parent_asin'])) >= 2:\n",
    "        found_user = user\n",
    "        break # 找到第一个就停止\n",
    "\n",
    "if found_user is not None:\n",
    "    print(\"--- Found a valid and meaningful user history for testing ---\")\n",
    "    \n",
    "    # 提取前两个【不重复】的商品作为我们的测试输入\n",
    "    distinct_items = []\n",
    "    seen_ids = set()\n",
    "    \n",
    "    # 将用户的历史记录打包在一起遍历\n",
    "    for item_id, text, image in zip(found_user['parent_asin'], found_user['combined_text'], found_user['image_url']):\n",
    "        if item_id not in seen_ids:\n",
    "            distinct_items.append({'parent_asin': item_id, 'combined_text': text, 'image_url': image})\n",
    "            seen_ids.add(item_id)\n",
    "        if len(distinct_items) == 2:\n",
    "            break\n",
    "            \n",
    "    # 打印成我们可以直接复制的 jsonl 格式\n",
    "    print(\"\\n=== Please copy the following content into test_user_history.txt ===\\n\")\n",
    "    for item in distinct_items:\n",
    "        # 使用 json.dumps 来处理文本中的特殊字符，避免格式错误\n",
    "        import json\n",
    "        print(json.dumps(item))\n",
    "\n",
    "else:\n",
    "    print(\"Could not find a user with at least two different items in their history in the current data sample.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410ee9f9-7cc9-456f-8797-c9a9c61b34d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (jimmyenv)",
   "language": "python",
   "name": "jimmyenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
